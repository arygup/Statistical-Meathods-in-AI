{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import basefile as bf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import resample\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggingEnsembleClassifier: #gpt\n",
    "    def __init__(self, base_classifier, num_estimators, fraction_samples, bootstrap, voting):\n",
    "        self.base_classifier = base_classifier\n",
    "        self.num_estimators = num_estimators\n",
    "        self.estimators = []\n",
    "        self.sample_indices = []\n",
    "        self.fraction_samples = fraction_samples\n",
    "        self.bootstrap = bootstrap\n",
    "        self.voting = voting\n",
    "    def fit(self, X, y):        \n",
    "        X_reset = X.reset_index(drop=True) if isinstance(X, pd.DataFrame) else X\n",
    "        y_reset = y.reset_index(drop=True) if isinstance(y, pd.Series) else y\n",
    "        for nums in range(self.num_estimators):\n",
    "            if self.bootstrap:\n",
    "                indices = resample(np.arange(len(X_reset)), n_samples=int(self.fraction_samples * len(X_reset)))\n",
    "            else:\n",
    "                indices = np.random.choice(np.arange(len(X_reset)), size=int(self.fraction_samples * len(X_reset)), replace=False)\n",
    "            self.sample_indices.append(indices)\n",
    "            X_sampled, y_sampled = X_reset[indices], y_reset[indices]\n",
    "            base_model = None\n",
    "            if self.base_classifier == \"DT\":\n",
    "                base_model = DecisionTreeClassifier(max_depth=25, criterion=\"gini\") \n",
    "            elif self.base_classifier == \"LR\":\n",
    "                base_model = bf.MultinomialLogisticRegression(learning_rate = 0.1, max_iter = 2000)\n",
    "            elif self.base_classifier == \"MLP\":\n",
    "                base_model = bf.MLPClassifier(input_size=X.shape[1], hidden_layers=[10, 15], learning_rate=0.01, activation='tanh', epoch = 2000)\n",
    "            base_model.fit(X_sampled, y_sampled)\n",
    "            self.estimators.append(base_model)\n",
    "    def predict(self, X):       \n",
    "        if self.voting == 'HARD':\n",
    "            if self.base_classifier == \"MLP\":\n",
    "                estm = []\n",
    "                for estimators in self.estimators:\n",
    "                    estm.append(estimators.predict(X).flatten())\n",
    "                y_pred = []\n",
    "                for i in range(len(X)):\n",
    "                    y_pred.append(np.argmax(np.bincount([est[i] for est in estm])))\n",
    "                return np.array(y_pred)\n",
    "            predictions = [estimator.predict(X) for estimator in self.estimators]\n",
    "            predictions = np.array(predictions).T\n",
    "            y_pred = np.array([np.argmax(np.bincount(class_prediction)) for class_prediction in predictions])\n",
    "            return y_pred\n",
    "        elif self.voting == 'SOFT' and self.base_classifier == \"MLP\":\n",
    "            predictions = []\n",
    "            confidences = []\n",
    "            for estimator in self.estimators:\n",
    "                predictions.append(estimator.predict(X).flatten())\n",
    "                confidences.append(np.max(estimator.predict_proba(X), axis=1))\n",
    "            predictions = np.array(predictions).T\n",
    "            confidences = np.array(confidences).T\n",
    "            y_pred = []\n",
    "            for prediction, confidence in zip(predictions, confidences):\n",
    "                class_weights = {}\n",
    "                for pred, conf in zip(prediction, confidence):\n",
    "                    pred = int(pred)  # Convert to integer or another hashable type\n",
    "                    if pred not in class_weights:\n",
    "                        class_weights[pred] = 0\n",
    "                    class_weights[pred] += conf\n",
    "                y_pred.append(max(class_weights, key=class_weights.get))\n",
    "            return np.array(y_pred)\n",
    "        elif self.voting == 'SOFT':\n",
    "            predictions = [estimator.predict(X) for estimator in self.estimators]\n",
    "            confidences = [np.max(estimator.predict_proba(X), axis=1) for estimator in self.estimators]\n",
    "            predictions = np.array(predictions).T\n",
    "            confidences = np.array(confidences).T\n",
    "            y_pred = []\n",
    "            for prediction, confidence in zip(predictions, confidences):\n",
    "                class_weights = {}\n",
    "                for pred, conf in zip(prediction, confidence):\n",
    "                    if pred not in class_weights:\n",
    "                        class_weights[pred] = 0\n",
    "                    class_weights[pred] += conf\n",
    "                y_pred.append(max(class_weights, key=class_weights.get))\n",
    "            return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggingEnsembleRegression:\n",
    "    def __init__(self, base_model , num_estimators, fraction_samples, bootstrap, voting='hard'):\n",
    "        self.base_model = base_model\n",
    "        self.num_estimators = num_estimators\n",
    "        self.fraction_samples = fraction_samples\n",
    "        self.bootstrap = bootstrap\n",
    "        self.voting = voting\n",
    "        self.estimators = []\n",
    "        self.sample_indices = []\n",
    "    def fit(self, X, y):# gpt\n",
    "        X_reset = X.reset_index(drop=True) if isinstance(X, pd.DataFrame) else X\n",
    "        y_reset = y.reset_index(drop=True) if isinstance(y, pd.Series) else y\n",
    "        for nums in range(self.num_estimators):\n",
    "            if self.bootstrap:\n",
    "                indices = resample(np.arange(len(X_reset)), n_samples=int(self.fraction_samples * len(X_reset)))\n",
    "            else:\n",
    "                indices = np.random.choice(np.arange(len(X_reset)), size=int(self.fraction_samples * len(X_reset)), replace=False)\n",
    "            self.sample_indices.append(indices)\n",
    "            X_sampled, y_sampled = X_reset[indices], y_reset[indices]\n",
    "            base_model = None\n",
    "            if self.base_model == \"DT\":\n",
    "                base_model = bf.DecisionTreeRegression(max_depth=50, criterion=\"absolute_error\")\n",
    "            elif self.base_model == \"LR\":\n",
    "                base_model = bf.LinearRegression(learning_rate = 0.1, n_iterations = 2000)\n",
    "            elif self.base_model == \"MLP\":\n",
    "                base_model = bf.MLPRegressor(input_size=X.shape[1], hidden_layers=[10, 15], learning_rate=0.01, activation='tanh', epoch = 2000)             \n",
    "            base_model.fit(X_sampled, y_sampled)\n",
    "            # Estimate Confidence on the validation set!\n",
    "            base_model.confidence = np.mean(np.abs(base_model.predict(X_sampled).reshape(-1,) - y_sampled))\n",
    "            self.estimators.append(base_model)\n",
    "    def predict(self, X):\n",
    "        predictions = [estimator.predict(X) for estimator in self.estimators]\n",
    "        predictions = np.array(predictions)\n",
    "        if self.voting == 'SOFT':\n",
    "            weights = [math.exp(-estimator.confidence) for estimator in self.estimators]\n",
    "            return np.average(predictions, axis=0, weights=weights)\n",
    "        elif self.voting == 'HARD':\n",
    "            return np.mean(predictions, axis=0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
