{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-27T18:39:36.382045Z","iopub.status.busy":"2024-10-27T18:39:36.381256Z","iopub.status.idle":"2024-10-27T18:39:49.299689Z","shell.execute_reply":"2024-10-27T18:39:49.298408Z","shell.execute_reply.started":"2024-10-27T18:39:36.382010Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.3\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install evaluate"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-27T18:39:49.302807Z","iopub.status.busy":"2024-10-27T18:39:49.302047Z","iopub.status.idle":"2024-10-27T18:40:01.934545Z","shell.execute_reply":"2024-10-27T18:40:01.933378Z","shell.execute_reply.started":"2024-10-27T18:39:49.302758Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting trl\n","  Downloading trl-0.11.4-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.4.0)\n","Requirement already satisfied: transformers>=4.40.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.45.1)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.34.2)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (3.0.1)\n","Collecting tyro>=0.5.11 (from trl)\n","  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.6.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.25.1)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.20.0)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (4.66.4)\n","Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.1)\n","Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.2.2)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.40.0->trl) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n","Downloading trl-0.11.4-py3-none-any.whl (316 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Installing collected packages: shtab, tyro, trl\n","Successfully installed shtab-1.7.1 trl-0.11.4 tyro-0.8.14\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install trl"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-27T18:40:01.936367Z","iopub.status.busy":"2024-10-27T18:40:01.936037Z","iopub.status.idle":"2024-10-27T18:40:16.209275Z","shell.execute_reply":"2024-10-27T18:40:16.208112Z","shell.execute_reply.started":"2024-10-27T18:40:01.936334Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=55c79742fb397ad4c1f3c1375894a4453452b8ee867a822086a3973029fecb63\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install rouge_score"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-27T18:40:16.211778Z","iopub.status.busy":"2024-10-27T18:40:16.211440Z","iopub.status.idle":"2024-10-27T18:40:28.448874Z","shell.execute_reply":"2024-10-27T18:40:28.447660Z","shell.execute_reply.started":"2024-10-27T18:40:16.211743Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting peft\n","  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: peft\n","Successfully installed peft-0.13.2\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install peft"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-27T18:40:28.450757Z","iopub.status.busy":"2024-10-27T18:40:28.450428Z","iopub.status.idle":"2024-10-27T18:40:37.366291Z","shell.execute_reply":"2024-10-27T18:40:37.365337Z","shell.execute_reply.started":"2024-10-27T18:40:28.450724Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63ac7df886b94761abf297afa603b629","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01be4ca77ee14d52999e170b2ae1d412","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fabd2dda424d43dca68ec8d6f1a45621","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2SdpaAttention(\n","          (c_attn): Conv1D(nf=2304, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=768)\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D(nf=3072, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=3072)\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",")\n"]}],"source":["from transformers import AutoModelForCausalLM\n","\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n","print(model)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-27T18:40:37.368682Z","iopub.status.busy":"2024-10-27T18:40:37.367717Z","iopub.status.idle":"2024-10-27T18:40:37.382186Z","shell.execute_reply":"2024-10-27T18:40:37.381307Z","shell.execute_reply.started":"2024-10-27T18:40:37.368636Z"},"trusted":true},"outputs":[],"source":["from dataclasses import dataclass\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n","from typing import Any, Dict, List, Optional, Union\n","import torch\n","\n","@dataclass\n","class DataCollatorForCausalLM:\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","\n","    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n","        input_ids = [feature['input_ids'] for feature in features]\n","        labels = [feature['labels'] for feature in features]\n","\n","        batch_input = self.tokenizer.pad(\n","            {'input_ids': input_ids},\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors='pt',\n","        )\n","\n","        batch_labels = self.tokenizer.pad(\n","            {'input_ids': labels},\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors='pt',\n","        )\n","\n","        batch_labels['input_ids'][batch_labels['input_ids'] == self.tokenizer.pad_token_id] = -100\n","\n","        batch = {\n","            'input_ids': batch_input['input_ids'],\n","            'attention_mask': batch_input['attention_mask'],\n","            'labels': batch_labels['input_ids'],\n","        }\n","\n","        return batch\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-27T09:38:39.144561Z","iopub.status.busy":"2024-10-27T09:38:39.144156Z","iopub.status.idle":"2024-10-27T17:16:52.135476Z","shell.execute_reply":"2024-10-27T17:16:52.134464Z","shell.execute_reply.started":"2024-10-27T09:38:39.144521Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad21a2ee9eaf4664b2e56c41fd1e26ef","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/27000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af2bbeaa6e6045cb9492778bc078854c","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b2dafbe4f6e42129b2cfff6c10a3f81","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["trainable params: 589,824 || all params: 125,029,632 || trainable%: 0.4717\n"]},{"name":"stderr","output_type":"stream","text":["You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='135000' max='135000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [135000/135000 7:37:19, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.019300</td>\n","      <td>1.973467</td>\n","      <td>0.191700</td>\n","      <td>0.088500</td>\n","      <td>0.138100</td>\n","      <td>0.180000</td>\n","      <td>640.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.294900</td>\n","      <td>1.947959</td>\n","      <td>0.193100</td>\n","      <td>0.089700</td>\n","      <td>0.138900</td>\n","      <td>0.180600</td>\n","      <td>640.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.001500</td>\n","      <td>1.934737</td>\n","      <td>0.195000</td>\n","      <td>0.090800</td>\n","      <td>0.140800</td>\n","      <td>0.182900</td>\n","      <td>640.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.242600</td>\n","      <td>1.922721</td>\n","      <td>0.195300</td>\n","      <td>0.092400</td>\n","      <td>0.142200</td>\n","      <td>0.183700</td>\n","      <td>640.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.906900</td>\n","      <td>1.918046</td>\n","      <td>0.195000</td>\n","      <td>0.091100</td>\n","      <td>0.141200</td>\n","      <td>0.182300</td>\n","      <td>640.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.894600</td>\n","      <td>1.914614</td>\n","      <td>0.192300</td>\n","      <td>0.090700</td>\n","      <td>0.139700</td>\n","      <td>0.180600</td>\n","      <td>640.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.003600</td>\n","      <td>1.909324</td>\n","      <td>0.192900</td>\n","      <td>0.090600</td>\n","      <td>0.140400</td>\n","      <td>0.180900</td>\n","      <td>640.000000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.984100</td>\n","      <td>1.909751</td>\n","      <td>0.193000</td>\n","      <td>0.091900</td>\n","      <td>0.140600</td>\n","      <td>0.181700</td>\n","      <td>640.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.171300</td>\n","      <td>1.908407</td>\n","      <td>0.193300</td>\n","      <td>0.091400</td>\n","      <td>0.140600</td>\n","      <td>0.182000</td>\n","      <td>640.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.020100</td>\n","      <td>1.906913</td>\n","      <td>0.192800</td>\n","      <td>0.090800</td>\n","      <td>0.140300</td>\n","      <td>0.180900</td>\n","      <td>640.000000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=135000, training_loss=2.1187491038004556, metrics={'train_runtime': 27440.0836, 'train_samples_per_second': 9.84, 'train_steps_per_second': 4.92, 'total_flos': 8.111897389023437e+16, 'train_loss': 2.1187491038004556, 'epoch': 10.0})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import load_dataset\n","import random\n","import numpy as np\n","import evaluate\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n","    TrainingArguments,\n",")\n","from peft import LoraConfig, get_peft_model\n","from trl import SFTTrainer\n","\n","rouge = evaluate.load(\"rouge\")\n","\n","dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n","\n","num_train_samples = 27000\n","train_select = random.sample(range(len(dataset[\"train\"])), k=num_train_samples)\n","\n","num_validation_samples = 100\n","validation_select = random.sample(range(len(dataset[\"validation\"])), k=num_validation_samples)\n","\n","num_test_samples = 100\n","test_select = random.sample(range(len(dataset[\"test\"])), k=num_test_samples)\n","\n","dataset_train = dataset[\"train\"].select(train_select)\n","dataset_validation = dataset[\"validation\"].select(validation_select)\n","dataset_test = dataset[\"test\"].select(test_select)\n","\n","model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","def preprocess_function(examples):\n","    prefix = \"summarize: \"\n","    inputs = [prefix + doc for doc in examples[\"article\"]]\n","    targets = [ex for ex in examples[\"highlights\"]]\n","\n","    max_source_length = 512  \n","    max_target_length = 128  \n","\n","    tokenized_inputs = tokenizer(\n","        inputs, max_length=max_source_length, truncation=True, padding=False\n","    )\n","    tokenized_targets = tokenizer(\n","        targets, max_length=max_target_length, truncation=True, padding=False\n","    )\n","\n","    input_ids = []\n","    labels = []\n","    for i in range(len(tokenized_inputs[\"input_ids\"])):\n","        input_ids_input = tokenized_inputs[\"input_ids\"][i]\n","        input_ids_target = tokenized_targets[\"input_ids\"][i]\n","\n","        input_ids_combined = input_ids_input + input_ids_target\n","        input_ids_combined = input_ids_combined[:1024]  \n","        input_ids.append(input_ids_combined)\n","\n","        labels_combined = [-100] * len(input_ids_input) + input_ids_target\n","        labels_combined = labels_combined[:1024]  \n","        labels.append(labels_combined)\n","\n","    model_inputs = {\n","        \"input_ids\": input_ids,\n","        \"labels\": labels\n","    }\n","\n","    return model_inputs\n","\n","tokenized_train = dataset_train.map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=dataset[\"train\"].column_names,\n",")\n","\n","tokenized_validation = dataset_validation.map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=dataset[\"validation\"].column_names,\n",")\n","\n","tokenized_test = dataset_test.map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=dataset[\"test\"].column_names,\n",")\n","\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    target_modules=[\"c_attn\"],\n","    lora_dropout=0.1,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, lora_config)\n","\n","model.print_trainable_parameters()\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=-1)\n","\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    result = rouge.compute(\n","        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n","    )\n","\n","    prediction_lens = [\n","        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions\n","    ]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    return {k: round(v, 4) for k, v in result.items()}\n","\n","data_collator = DataCollatorForCausalLM(tokenizer=tokenizer, padding='longest')\n","\n","training_args = TrainingArguments(\n","    output_dir=\"gpt2_lora_test\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-4,\n","    per_device_train_batch_size=2,  \n","    per_device_eval_batch_size=2,   \n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=10,\n","    report_to=\"none\",\n","    logging_steps=10,\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    eval_accumulation_steps=2\n",")\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_validation,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-27T18:54:30.557879Z","iopub.status.busy":"2024-10-27T18:54:30.557461Z","iopub.status.idle":"2024-10-28T03:21:50.257216Z","shell.execute_reply":"2024-10-28T03:21:50.256153Z","shell.execute_reply.started":"2024-10-27T18:54:30.557838Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7230d74784e468e9ade6e96bd5941df","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='36000' max='36000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [36000/36000 8:27:16, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>8.685900</td>\n","      <td>9.335599</td>\n","      <td>0.084700</td>\n","      <td>0.009400</td>\n","      <td>0.064500</td>\n","      <td>0.081500</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>8.396700</td>\n","      <td>8.931857</td>\n","      <td>0.086300</td>\n","      <td>0.008700</td>\n","      <td>0.065200</td>\n","      <td>0.082400</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>8.230400</td>\n","      <td>8.612606</td>\n","      <td>0.088100</td>\n","      <td>0.008500</td>\n","      <td>0.066000</td>\n","      <td>0.084300</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>8.035900</td>\n","      <td>8.389034</td>\n","      <td>0.088200</td>\n","      <td>0.008100</td>\n","      <td>0.066000</td>\n","      <td>0.084400</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>7.875800</td>\n","      <td>8.204077</td>\n","      <td>0.087700</td>\n","      <td>0.007900</td>\n","      <td>0.066300</td>\n","      <td>0.084500</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>7.784300</td>\n","      <td>8.057652</td>\n","      <td>0.087900</td>\n","      <td>0.008000</td>\n","      <td>0.066400</td>\n","      <td>0.084900</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>7.679600</td>\n","      <td>7.930903</td>\n","      <td>0.088100</td>\n","      <td>0.007400</td>\n","      <td>0.066100</td>\n","      <td>0.084700</td>\n","      <td>399.990000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>7.599900</td>\n","      <td>7.831755</td>\n","      <td>0.088600</td>\n","      <td>0.007200</td>\n","      <td>0.066500</td>\n","      <td>0.085100</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>7.520200</td>\n","      <td>7.745013</td>\n","      <td>0.089000</td>\n","      <td>0.007100</td>\n","      <td>0.066600</td>\n","      <td>0.085600</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>7.447700</td>\n","      <td>7.676820</td>\n","      <td>0.089200</td>\n","      <td>0.007600</td>\n","      <td>0.066300</td>\n","      <td>0.085700</td>\n","      <td>400.000000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>7.392300</td>\n","      <td>7.605418</td>\n","      <td>0.088900</td>\n","      <td>0.007200</td>\n","      <td>0.066300</td>\n","      <td>0.085100</td>\n","      <td>399.980000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>7.329600</td>\n","      <td>7.550833</td>\n","      <td>0.088300</td>\n","      <td>0.007300</td>\n","      <td>0.066300</td>\n","      <td>0.084300</td>\n","      <td>399.980000</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>7.303500</td>\n","      <td>7.505110</td>\n","      <td>0.089400</td>\n","      <td>0.007100</td>\n","      <td>0.066700</td>\n","      <td>0.085600</td>\n","      <td>399.990000</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>7.254900</td>\n","      <td>7.464031</td>\n","      <td>0.088500</td>\n","      <td>0.007200</td>\n","      <td>0.066400</td>\n","      <td>0.084900</td>\n","      <td>399.980000</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>7.216800</td>\n","      <td>7.428802</td>\n","      <td>0.088700</td>\n","      <td>0.007100</td>\n","      <td>0.066200</td>\n","      <td>0.085500</td>\n","      <td>399.980000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>7.192600</td>\n","      <td>7.399335</td>\n","      <td>0.088000</td>\n","      <td>0.007200</td>\n","      <td>0.066000</td>\n","      <td>0.084600</td>\n","      <td>399.980000</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>7.162100</td>\n","      <td>7.377441</td>\n","      <td>0.088600</td>\n","      <td>0.007200</td>\n","      <td>0.066100</td>\n","      <td>0.085000</td>\n","      <td>399.980000</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>7.159800</td>\n","      <td>7.362363</td>\n","      <td>0.087400</td>\n","      <td>0.007300</td>\n","      <td>0.065700</td>\n","      <td>0.084000</td>\n","      <td>399.980000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>7.141400</td>\n","      <td>7.353936</td>\n","      <td>0.087100</td>\n","      <td>0.007100</td>\n","      <td>0.065200</td>\n","      <td>0.083800</td>\n","      <td>399.980000</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>7.140100</td>\n","      <td>7.350389</td>\n","      <td>0.087100</td>\n","      <td>0.007100</td>\n","      <td>0.065600</td>\n","      <td>0.083600</td>\n","      <td>399.980000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=36000, training_loss=7.597370930989583, metrics={'train_runtime': 30437.1879, 'train_samples_per_second': 17.741, 'train_steps_per_second': 1.183, 'total_flos': 0.0, 'train_loss': 7.597370930989583, 'epoch': 20.0})"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import load_dataset\n","import random\n","from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorWithPadding, TrainingArguments\n","import numpy as np\n","import evaluate\n","from trl import SFTTrainer\n","import torch\n","import torch.nn as nn\n","from dataclasses import dataclass\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n","from typing import Any, Dict, List, Optional, Union\n","import torch\n","\n","rouge = evaluate.load(\"rouge\")\n","\n","data_files = {\"train\": \"train.csv\", \"test\": \"test.csv\", \"validation\": \"validation.csv\"}\n","dataset = load_dataset(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail\", data_files=data_files)\n","num_train_samples = 27000\n","train_select = random.sample(range(len(dataset[\"train\"])), k=num_train_samples)\n","\n","num_validation_samples = 100\n","validation_select = random.sample(range(len(dataset[\"validation\"])), k=num_validation_samples)\n","\n","num_test_samples = 100\n","test_select = random.sample(range(len(dataset[\"test\"])), k=num_test_samples)\n","\n","dataset_train = dataset[\"train\"].select(train_select)\n","dataset_validation = dataset[\"validation\"].select(validation_select)\n","dataset_test = dataset[\"test\"].select(test_select)\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","num_soft_tokens = 20  \n","embedding_size = 768  \n","\n","class GPT2WithSoftPrompt(nn.Module):\n","    def __init__(self, base_model, num_soft_tokens):\n","        super().__init__()\n","        self.base_model = base_model\n","        self.num_soft_tokens = num_soft_tokens\n","        self.soft_prompt_embeddings = nn.Parameter(torch.randn(num_soft_tokens, base_model.config.hidden_size))\n","        for param in self.base_model.parameters():\n","            param.requires_grad = False\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels=None):\n","        input_embeds = self.base_model.transformer.wte(input_ids)\n","        batch_size = input_ids.size(0)\n","        soft_prompt_embeds = self.soft_prompt_embeddings.unsqueeze(0).expand(batch_size, -1, -1)\n","        inputs_embeds = torch.cat([soft_prompt_embeds, input_embeds], dim=1)\n","        if attention_mask is not None:\n","            soft_prompt_mask = torch.ones(batch_size, self.num_soft_tokens, dtype=attention_mask.dtype, device=attention_mask.device)\n","            attention_mask = torch.cat([soft_prompt_mask, attention_mask], dim=1)\n","        if labels is not None:\n","            soft_prompt_labels = torch.full((batch_size, self.num_soft_tokens), -100, dtype=labels.dtype, device=labels.device)\n","            labels = torch.cat([soft_prompt_labels, labels], dim=1)\n","        position_ids = torch.arange(inputs_embeds.size(1), dtype=torch.long, device=inputs_embeds.device)\n","        position_ids = position_ids.unsqueeze(0).expand(batch_size, -1)\n","        outputs = self.base_model(\n","            inputs_embeds=inputs_embeds,\n","            attention_mask=attention_mask,\n","            labels=labels,\n","            position_ids=position_ids,\n","        )\n","        return outputs\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n","model = GPT2WithSoftPrompt(base_model, num_soft_tokens=num_soft_tokens)\n","\n","\n","def preprocess_function(examples):\n","    inputs = examples[\"article\"]\n","    model_inputs = tokenizer(inputs, max_length=400, truncation=True, padding='max_length')\n","    labels = tokenizer(text_target=examples[\"highlights\"], max_length=400, truncation=True, padding='max_length')\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_train = dataset_train.map(preprocess_function, batched=True)\n","tokenized_validation = dataset_validation.map(preprocess_function, batched=True)\n","tokenized_test = dataset_test.map(preprocess_function, batched=True)\n","\n","def compute_metrics(eval_pred):\n","    predictions = eval_pred.predictions\n","    labels = eval_pred.label_ids\n","    \n","    if isinstance(predictions, tuple):\n","        predictions = predictions[0]\n","    \n","    predictions = predictions[:, num_soft_tokens:, :]\n","    labels = labels[:, num_soft_tokens:]\n","    \n","    predictions = np.argmax(predictions, axis=-1)\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    \n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    \n","    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    \n","    return {k: round(v, 4) for k, v in result.items()}\n","\n","\n","\n","training_args = TrainingArguments(\n","    output_dir=\"gpt2_soft_prompt\",\n","    eval_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=15,\n","    per_device_eval_batch_size=1,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=20,\n","    report_to=\"none\",\n","    fp16=True,\n","    eval_accumulation_steps=1,\n","    save_safetensors=False,\n",")\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=tokenized_train, \n","    eval_dataset=tokenized_validation,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    compute_metrics=compute_metrics,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1654566,"sourceId":2734496,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
